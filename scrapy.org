
* 2 steps

  http://doc.scrapy.org/en/1.0/intro/tutorial.html

|  2 | steps                        |                                         |
|    |                              |                                         |
|----+------------------------------+-----------------------------------------|
| 10 | Creating a project structure |                                         |
| 12 |                              | view the project structure (optional)   |
| 14 |                              | delete the project structure (optional) |
|    |                              |                                         |
|----+------------------------------+-----------------------------------------|
| 20 | item.py                      |                                         |
| 22 |                              | view item.py (optional)                 |
|    |                              |                                         |
|----+------------------------------+-----------------------------------------|
| 30 | dmoz_spider.py               |                                         |
| 32 |                              | view dmoz_spider.py (optional)          |
|    |                              |                                         |
|----+------------------------------+-----------------------------------------|
| 40 | crawling                     |                                         |
| 42 |                              | view product files                      |
|    |                              |                                         |
|----+------------------------------+-----------------------------------------|
| 95 | blank sh babel block         |                                         |


* 10 Creating a project structure


#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

scrapy startproject tutorial

#+END_SRC

** 12 view the project structure (optional)

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

tree tutorial

#+END_SRC


** 14 delete the project structure (optional)

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

rm -r tutorial

ls tutorial

#+END_SRC


* 20 item.py


#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

cat > tutorial/tutorial/items.py << EOF

import scrapy

class DmozItem(scrapy.Item):
    title = scrapy.Field()
    link = scrapy.Field()
    desc = scrapy.Field()

EOF

#+END_SRC


** view item.py (optional)

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

cat tutorial/tutorial/items.py

#+END_SRC


* 30 dmoz_spider.py

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

cat > tutorial/tutorial/spiders/dmoz_spider.py << EOF

import scrapy

class DmozSpider(scrapy.Spider):
    name = "dmoz"
    allowed_domains = ["dmoz.org"]
    start_urls = [
        "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/",
        "http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"
    ]

    def parse(self, response):
        filename = response.url.split("/")[-2] + '.html'
        with open(filename, 'wb') as f:
            f.write(response.body)

EOF

#+END_SRC


** 32 view dmoz_spider.py (optional)

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

cat  tutorial/tutorial/spiders/dmoz_spider.py 

#+END_SRC


* 40 crawling

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

cd tutorial

scrapy crawl dmoz

#+END_SRC


** 42 view product files (optional)

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh

ls tutorial

#+END_SRC


* 95 blank sh babel block

#+HEADERS:  :results silent
#+HEADERS:  :results raw
#+BEGIN_SRC sh


#+END_SRC
